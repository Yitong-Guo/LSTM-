{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86ed4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import give_valid_test\n",
    "import _pickle as cpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd991748",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a8f7ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(train_path, word2number_dict, batch_size, n_step):\n",
    "    all_input_batch = []\n",
    "    all_target_batch = []\n",
    "\n",
    "    text = open(train_path, 'r', encoding='utf-8') #open the file\n",
    "\n",
    "    input_batch = []\n",
    "    target_batch = []\n",
    "    for sen in text:\n",
    "        word = sen.strip().split(\" \")  # space tokenizer\n",
    "        word = [\"<sos>\"] + word\n",
    "        word = word + [\"<eos>\"]\n",
    "\n",
    "        if len(word) <= n_step:   #pad the sentence\n",
    "            word = [\"<pad>\"]*(n_step+1-len(word)) + word\n",
    "\n",
    "        for word_index in range(len(word)-n_step):\n",
    "            input = [word2number_dict[n] for n in word[word_index:word_index+n_step]]  # create (1~n-1) as input\n",
    "            target = word2number_dict[word[word_index+n_step]]  # create (n) as target, We usually call this 'casual language model'\n",
    "            input_batch.append(input)\n",
    "            target_batch.append(target)\n",
    "\n",
    "            if len(input_batch) == batch_size:\n",
    "                all_input_batch.append(input_batch)\n",
    "                all_target_batch.append(target_batch)\n",
    "                input_batch = []\n",
    "                target_batch = []\n",
    "\n",
    "    return all_input_batch, all_target_batch # (batch num, batch size, n_step) (batch num, batch size)\n",
    "\n",
    "def make_dict(train_path):\n",
    "    text = open(train_path, 'r', encoding='utf-8')  #open the train file\n",
    "    word_list = set()  # a set for making dict\n",
    "\n",
    "    for line in text:\n",
    "        line = line.strip().split(\" \")\n",
    "        word_list = word_list.union(set(line))\n",
    "\n",
    "    word_list = list(sorted(word_list))   #set to list\n",
    "\n",
    "    word2number_dict = {w: i+2 for i, w in enumerate(word_list)}\n",
    "    number2word_dict = {i+2: w for i, w in enumerate(word_list)}\n",
    "\n",
    "    #add the <pad> and <unk_word>\n",
    "    word2number_dict[\"<pad>\"] = 0\n",
    "    number2word_dict[0] = \"<pad>\"\n",
    "    word2number_dict[\"<unk_word>\"] = 1\n",
    "    number2word_dict[1] = \"<unk_word>\"\n",
    "    word2number_dict[\"<sos>\"] = 2\n",
    "    number2word_dict[2] = \"<sos>\"\n",
    "    word2number_dict[\"<eos>\"] = 3\n",
    "    number2word_dict[3] = \"<eos>\"\n",
    "\n",
    "    return word2number_dict, number2word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea56c24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveCustomLSTM(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        #i_t\n",
    "        self.W_i = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_i = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_i = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        #f_t\n",
    "        self.W_f = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_f = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_f = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        #c_t\n",
    "        self.W_c = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_c = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_c = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        #o_t\n",
    "        self.W_o = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_o = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_o = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        ###############################3\n",
    "        #i_t\n",
    "        self.W_i2 = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_i2 = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_i2 = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        #f_t\n",
    "        self.W_f2 = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_f2 = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_f2 = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        #c_t\n",
    "        self.W_c2 = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_c2 = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_c2 = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        #o_t\n",
    "        self.W_o2 = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_o2 = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_o2 = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    def forward(self,\n",
    "                x,\n",
    "                init_states=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        assumes x.shape represents (batch_size, sequence_size, input_size)\n",
    "        \"\"\"\n",
    "        bs, seq_sz, _ = x.size()\n",
    "        hidden_seq = []\n",
    "        \n",
    "        if init_states is None:\n",
    "            h_t, c_t, h_t2, c_t2 = (\n",
    "                torch.zeros(bs, self.hidden_size).to(x.device),\n",
    "                torch.zeros(bs, self.hidden_size).to(x.device),\n",
    "                torch.zeros(bs, self.hidden_size).to(x.device),\n",
    "                torch.zeros(bs, self.hidden_size).to(x.device),\n",
    "            )\n",
    "        else:\n",
    "            h_t, c_t, h_t2, c_t2 = init_states\n",
    "            \n",
    "        for t in range(seq_sz):\n",
    "            x_t = x[:, t, :]\n",
    "            \n",
    "            i_t = torch.sigmoid(x_t @ self.W_i + h_t @ self.U_i + self.b_i)\n",
    "            f_t = torch.sigmoid(x_t @ self.W_f + h_t @ self.U_f + self.b_f)\n",
    "            g_t = torch.tanh(x_t @ self.W_c + h_t @ self.U_c + self.b_c)\n",
    "            o_t = torch.sigmoid(x_t @ self.W_o + h_t @ self.U_o + self.b_o)\n",
    "            c_t = f_t * c_t + i_t * g_t\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "            ##############################\n",
    "            i_t2 = torch.sigmoid(x_t @ self.W_i2 + h_t2 @ self.U_i2 + self.b_i2)\n",
    "            f_t2 = torch.sigmoid(x_t @ self.W_f2 + h_t2 @ self.U_f2 + self.b_f2)\n",
    "            g_t2 = torch.tanh(x_t @ self.W_c2 + h_t2 @ self.U_c2 + self.b_c2)\n",
    "            o_t2 = torch.sigmoid(x_t @ self.W_o2 + h_t2 @ self.U_o2 + self.b_o2)\n",
    "            c_t2 = f_t2 * c_t2 + i_t2 * g_t2\n",
    "            h_t2 = o_t2 * torch.tanh(c_t2)\n",
    "            \n",
    "            hidden_seq.append(h_t2.unsqueeze(0))\n",
    "        \n",
    "        #reshape hidden_seq p/ retornar\n",
    "        hidden_seq = torch.cat(hidden_seq, dim=0)\n",
    "        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n",
    "        return hidden_seq, (h_t, c_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d2960a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.C = nn.Embedding(n_class, embedding_dim=emb_size)\n",
    "        self.LSTM = NaiveCustomLSTM(input_size=emb_size, hidden_size=n_hidden)\n",
    "        self.W = nn.Linear(n_hidden, n_class, bias=False)\n",
    "        self.b = nn.Parameter(torch.ones([n_class]))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.C(X)\n",
    "        X = X.transpose(0, 1) \n",
    "        outputs, (_, _) = self.LSTM(X)\n",
    "        outputs = outputs[-1] \n",
    "        model = self.W(outputs) + self.b \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "148a7172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LSTMlm():\n",
    "    model = Net()\n",
    "    model.to(device)\n",
    "    print(model)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    # Training\n",
    "    batch_number = len(all_input_batch)\n",
    "    for epoch in range(all_epoch):\n",
    "        count_batch = 0\n",
    "        for input_batch, target_batch in zip(all_input_batch, all_target_batch):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # input_batch : [batch_size, n_step, n_class]\n",
    "            output = model(input_batch)\n",
    "\n",
    "            # output : [batch_size, n_class], target_batch : [batch_size] (LongTensor, not one-hot)\n",
    "            loss = criterion(output, target_batch)\n",
    "            ppl = math.exp(loss.item())\n",
    "            if (count_batch + 1) % 100 == 0:\n",
    "                print('Epoch:', '%04d' % (epoch + 1), 'Batch:', '%02d' % (count_batch + 1), f'/{batch_number}',\n",
    "                      'loss =', '{:.6f}'.format(loss), 'ppl =', '{:.6}'.format(ppl))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            count_batch += 1\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'Batch:', '%02d' % (count_batch + 1), f'/{batch_number}',\n",
    "                'loss =', '{:.6f}'.format(loss), 'ppl =', '{:.6}'.format(ppl))\n",
    "\n",
    "        # valid after training one epoch\n",
    "        all_valid_batch, all_valid_target = give_valid_test.give_valid(word2number_dict, n_step)\n",
    "        all_valid_batch = torch.LongTensor(all_valid_batch).to(device)  # list to tensor\n",
    "        all_valid_target = torch.LongTensor(all_valid_target).to(device)\n",
    "\n",
    "        total_valid = len(all_valid_target)*128  # valid and test batch size is 128\n",
    "        with torch.no_grad():\n",
    "            total_loss = 0\n",
    "            count_loss = 0\n",
    "            for valid_batch, valid_target in zip(all_valid_batch, all_valid_target):\n",
    "                valid_output = model(valid_batch)\n",
    "                valid_loss = criterion(valid_output, valid_target)\n",
    "                total_loss += valid_loss.item()\n",
    "                count_loss += 1\n",
    "          \n",
    "            print(f'Valid {total_valid} samples after epoch:', '%04d' % (epoch + 1), 'loss =',\n",
    "                  '{:.6f}'.format(total_loss / count_loss),\n",
    "                  'ppl =', '{:.6}'.format(math.exp(total_loss / count_loss)))\n",
    "\n",
    "        if (epoch+1) % save_checkpoint_epoch == 0:\n",
    "            torch.save(model, f'LSTMlm_model_epoch{epoch+1}.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e45bfe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_LSTMlm(select_model_path):\n",
    "    model = torch.load(select_model_path, map_location=\"cpu\")  #load the selected model\n",
    "    model.to(device)\n",
    "\n",
    "    #load the test data\n",
    "    all_test_batch, all_test_target = give_valid_test.give_test(word2number_dict, n_step)\n",
    "    all_test_batch = torch.LongTensor(all_test_batch).to(device)  # list to tensor\n",
    "    all_test_target = torch.LongTensor(all_test_target).to(device)\n",
    "    total_test = len(all_test_target)*128  # valid and test batch size is 128\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    total_loss = 0\n",
    "    count_loss = 0\n",
    "    for test_batch, test_target in zip(all_test_batch, all_test_target):\n",
    "        test_output = model(test_batch)\n",
    "        test_loss = criterion(test_output, test_target)\n",
    "        total_loss += test_loss.item()\n",
    "        count_loss += 1\n",
    "\n",
    "    print(f\"Test {total_test} samples with {select_model_path}……………………\")\n",
    "    print('loss =','{:.6f}'.format(total_loss / count_loss),\n",
    "                  'ppl =', '{:.6}'.format(math.exp(total_loss / count_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a01f3f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print parameter ......\n",
      "n_step: 5\n",
      "n_hidden: 128\n",
      "batch_size: 128\n",
      "learn_rate: 0.0005\n",
      "all_epoch: 5\n",
      "emb_size: 256\n",
      "save_checkpoint_epoch: 5\n",
      "The size of the dictionary is: 7615\n",
      "generating train_batch ......\n",
      "The number of the train batch is: 603\n",
      "\n",
      "Train the LSTMLM……………………\n",
      "Net(\n",
      "  (C): Embedding(7615, 256)\n",
      "  (LSTM): NaiveCustomLSTM()\n",
      "  (W): Linear(in_features=128, out_features=7615, bias=False)\n",
      ")\n",
      "Epoch: 0001 Batch: 100 /603 loss = 6.627302 ppl = 755.441\n",
      "Epoch: 0001 Batch: 200 /603 loss = 6.365810 ppl = 581.616\n",
      "Epoch: 0001 Batch: 300 /603 loss = 6.498100 ppl = 663.879\n",
      "Epoch: 0001 Batch: 400 /603 loss = 6.797557 ppl = 895.656\n",
      "Epoch: 0001 Batch: 500 /603 loss = 6.260495 ppl = 523.478\n",
      "Epoch: 0001 Batch: 600 /603 loss = 6.400978 ppl = 602.434\n",
      "Epoch: 0001 Batch: 604 /603 loss = 5.785347 ppl = 325.495\n",
      "Valid 5504 samples after epoch: 0001 loss = 6.235954 ppl = 510.788\n",
      "Epoch: 0002 Batch: 100 /603 loss = 5.955477 ppl = 385.861\n",
      "Epoch: 0002 Batch: 200 /603 loss = 5.886454 ppl = 360.126\n",
      "Epoch: 0002 Batch: 300 /603 loss = 6.103232 ppl = 447.301\n",
      "Epoch: 0002 Batch: 400 /603 loss = 6.472307 ppl = 646.974\n",
      "Epoch: 0002 Batch: 500 /603 loss = 5.991853 ppl = 400.156\n",
      "Epoch: 0002 Batch: 600 /603 loss = 6.100402 ppl = 446.037\n",
      "Epoch: 0002 Batch: 604 /603 loss = 5.489665 ppl = 242.176\n",
      "Valid 5504 samples after epoch: 0002 loss = 6.066768 ppl = 431.285\n",
      "Epoch: 0003 Batch: 100 /603 loss = 5.784717 ppl = 325.29\n",
      "Epoch: 0003 Batch: 200 /603 loss = 5.572897 ppl = 263.196\n",
      "Epoch: 0003 Batch: 300 /603 loss = 5.851305 ppl = 347.688\n",
      "Epoch: 0003 Batch: 400 /603 loss = 6.214250 ppl = 499.821\n",
      "Epoch: 0003 Batch: 500 /603 loss = 5.799072 ppl = 329.993\n",
      "Epoch: 0003 Batch: 600 /603 loss = 5.872522 ppl = 355.144\n",
      "Epoch: 0003 Batch: 604 /603 loss = 5.284640 ppl = 197.283\n",
      "Valid 5504 samples after epoch: 0003 loss = 5.961611 ppl = 388.235\n",
      "Epoch: 0004 Batch: 100 /603 loss = 5.608900 ppl = 272.844\n",
      "Epoch: 0004 Batch: 200 /603 loss = 5.320738 ppl = 204.535\n",
      "Epoch: 0004 Batch: 300 /603 loss = 5.630795 ppl = 278.884\n",
      "Epoch: 0004 Batch: 400 /603 loss = 5.977468 ppl = 394.44\n",
      "Epoch: 0004 Batch: 500 /603 loss = 5.631803 ppl = 279.165\n",
      "Epoch: 0004 Batch: 600 /603 loss = 5.660945 ppl = 287.42\n",
      "Epoch: 0004 Batch: 604 /603 loss = 5.121038 ppl = 167.509\n",
      "Valid 5504 samples after epoch: 0004 loss = 5.893140 ppl = 362.542\n",
      "Epoch: 0005 Batch: 100 /603 loss = 5.435689 ppl = 229.451\n",
      "Epoch: 0005 Batch: 200 /603 loss = 5.115476 ppl = 166.58\n",
      "Epoch: 0005 Batch: 300 /603 loss = 5.433666 ppl = 228.987\n",
      "Epoch: 0005 Batch: 400 /603 loss = 5.757399 ppl = 316.524\n",
      "Epoch: 0005 Batch: 500 /603 loss = 5.481781 ppl = 240.274\n",
      "Epoch: 0005 Batch: 600 /603 loss = 5.456762 ppl = 234.337\n",
      "Epoch: 0005 Batch: 604 /603 loss = 4.972225 ppl = 144.348\n",
      "Valid 5504 samples after epoch: 0005 loss = 5.847297 ppl = 346.297\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    n_step = 5 # number of cells(= number of Step)\n",
    "    n_hidden = 128 # number of hidden units in one cell\n",
    "    batch_size = 128 # batch size\n",
    "    learn_rate = 0.0005\n",
    "    all_epoch = 5 #the all epoch for training\n",
    "    emb_size = 256 #embeding size\n",
    "    save_checkpoint_epoch = 5 # save a checkpoint per save_checkpoint_epoch epochs !!! Note the save path !!!\n",
    "    data_root = ''\n",
    "    train_path = os.path.join(data_root, 'train.txt') # the path of train dataset\n",
    "\n",
    "    print(\"print parameter ......\")\n",
    "    print(\"n_step:\", n_step)\n",
    "    print(\"n_hidden:\", n_hidden)\n",
    "    print(\"batch_size:\", batch_size)\n",
    "    print(\"learn_rate:\", learn_rate)\n",
    "    print(\"all_epoch:\", all_epoch)\n",
    "    print(\"emb_size:\", emb_size)\n",
    "    print(\"save_checkpoint_epoch:\", save_checkpoint_epoch)\n",
    "    #print(\"train_data:\", data_root)\n",
    "\n",
    "    word2number_dict, number2word_dict = make_dict(train_path)\n",
    "    #print(word2number_dict)\n",
    "\n",
    "    print(\"The size of the dictionary is:\", len(word2number_dict))\n",
    "    n_class = len(word2number_dict)  #n_class (= dict size)\n",
    "\n",
    "    print(\"generating train_batch ......\")\n",
    "    all_input_batch, all_target_batch = make_batch(train_path, word2number_dict, batch_size, n_step)  # make the batch\n",
    "    train_batch_list = [all_input_batch, all_target_batch]\n",
    "    \n",
    "    print(\"The number of the train batch is:\", len(all_input_batch))\n",
    "    all_input_batch = torch.LongTensor(all_input_batch).to(device)   #list to tensor\n",
    "    all_target_batch = torch.LongTensor(all_target_batch).to(device)\n",
    "    # print(all_input_batch.shape)\n",
    "    # print(all_target_batch.shape)\n",
    "    all_input_batch = all_input_batch.reshape(-1, batch_size, n_step)\n",
    "    all_target_batch = all_target_batch.reshape(-1, batch_size)\n",
    "\n",
    "    print(\"\\nTrain the LSTMLM……………………\")\n",
    "    train_LSTMlm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f760c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test the LSTMLM……………………\n",
      "Test 6528 samples with LSTMlm_model_epoch5.ckpt……………………\n",
      "loss = 5.785444 ppl = 325.527\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTest the LSTMLM……………………\")\n",
    "select_model_path = \"LSTMlm_model_epoch5.ckpt\"\n",
    "test_LSTMlm(select_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffbeffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
