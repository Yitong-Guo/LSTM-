{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b37d433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import give_valid_test\n",
    "import _pickle as cpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "037f42eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00a8a329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(train_path, word2number_dict, batch_size, n_step):\n",
    "    all_input_batch = []\n",
    "    all_target_batch = []\n",
    "\n",
    "    text = open(train_path, 'r', encoding='utf-8') #open the file\n",
    "\n",
    "    input_batch = []\n",
    "    target_batch = []\n",
    "    for sen in text:\n",
    "        word = sen.strip().split(\" \")  # space tokenizer\n",
    "        word = [\"<sos>\"] + word\n",
    "        word = word + [\"<eos>\"]\n",
    "\n",
    "        if len(word) <= n_step:   #pad the sentence\n",
    "            word = [\"<pad>\"]*(n_step+1-len(word)) + word\n",
    "\n",
    "        for word_index in range(len(word)-n_step):\n",
    "            input = [word2number_dict[n] for n in word[word_index:word_index+n_step]]  # create (1~n-1) as input\n",
    "            target = word2number_dict[word[word_index+n_step]]  # create (n) as target, We usually call this 'casual language model'\n",
    "            input_batch.append(input)\n",
    "            target_batch.append(target)\n",
    "\n",
    "            if len(input_batch) == batch_size:\n",
    "                all_input_batch.append(input_batch)\n",
    "                all_target_batch.append(target_batch)\n",
    "                input_batch = []\n",
    "                target_batch = []\n",
    "\n",
    "    return all_input_batch, all_target_batch # (batch num, batch size, n_step) (batch num, batch size)\n",
    "\n",
    "def make_dict(train_path):\n",
    "    text = open(train_path, 'r', encoding='utf-8')  #open the train file\n",
    "    word_list = set()  # a set for making dict\n",
    "\n",
    "    for line in text:\n",
    "        line = line.strip().split(\" \")\n",
    "        word_list = word_list.union(set(line))\n",
    "\n",
    "    word_list = list(sorted(word_list))   #set to list\n",
    "\n",
    "    word2number_dict = {w: i+2 for i, w in enumerate(word_list)}\n",
    "    number2word_dict = {i+2: w for i, w in enumerate(word_list)}\n",
    "\n",
    "    #add the <pad> and <unk_word>\n",
    "    word2number_dict[\"<pad>\"] = 0\n",
    "    number2word_dict[0] = \"<pad>\"\n",
    "    word2number_dict[\"<unk_word>\"] = 1\n",
    "    number2word_dict[1] = \"<unk_word>\"\n",
    "    word2number_dict[\"<sos>\"] = 2\n",
    "    number2word_dict[2] = \"<sos>\"\n",
    "    word2number_dict[\"<eos>\"] = 3\n",
    "    number2word_dict[3] = \"<eos>\"\n",
    "\n",
    "    return word2number_dict, number2word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09930731",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveCustomLSTM(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        #i_t\n",
    "        self.W_i = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_i = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_i = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        #f_t\n",
    "        self.W_f = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_f = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_f = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        #c_t\n",
    "        self.W_c = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_c = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_c = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        #o_t\n",
    "        self.W_o = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_o = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_o = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    def forward(self,\n",
    "                x,\n",
    "                init_states=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        assumes x.shape represents (batch_size, sequence_size, input_size)\n",
    "        \"\"\"\n",
    "        bs, seq_sz, _ = x.size()\n",
    "        hidden_seq = []\n",
    "        \n",
    "        if init_states is None:\n",
    "            h_t, c_t = (\n",
    "                torch.zeros(bs, self.hidden_size).to(x.device),\n",
    "                torch.zeros(bs, self.hidden_size).to(x.device),\n",
    "            )\n",
    "        else:\n",
    "            h_t, c_t = init_states\n",
    "            \n",
    "        for t in range(seq_sz):\n",
    "            x_t = x[:, t, :]\n",
    "            \n",
    "            i_t = torch.sigmoid(x_t @ self.W_i + h_t @ self.U_i + self.b_i)\n",
    "            f_t = torch.sigmoid(x_t @ self.W_f + h_t @ self.U_f + self.b_f)\n",
    "            g_t = torch.tanh(x_t @ self.W_c + h_t @ self.U_c + self.b_c)\n",
    "            o_t = torch.sigmoid(x_t @ self.W_o + h_t @ self.U_o + self.b_o)\n",
    "            c_t = f_t * c_t + i_t * g_t\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "            \n",
    "            hidden_seq.append(h_t.unsqueeze(0))\n",
    "        \n",
    "        #reshape hidden_seq p/ retornar\n",
    "        hidden_seq = torch.cat(hidden_seq, dim=0)\n",
    "        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n",
    "        return hidden_seq, (h_t, c_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16feb320",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.C = nn.Embedding(n_class, embedding_dim=emb_size)\n",
    "        self.LSTM = NaiveCustomLSTM(input_size=emb_size, hidden_size=n_hidden)\n",
    "        self.W = nn.Linear(n_hidden, n_class, bias=False)\n",
    "        self.b = nn.Parameter(torch.ones([n_class]))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.C(X)\n",
    "        X = X.transpose(0, 1) \n",
    "        outputs, (_, _) = self.LSTM(X)\n",
    "        outputs = outputs[-1] \n",
    "        model = self.W(outputs) + self.b \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ead02597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LSTMlm():\n",
    "    model = Net()\n",
    "    model.to(device)\n",
    "    print(model)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    # Training\n",
    "    batch_number = len(all_input_batch)\n",
    "    for epoch in range(all_epoch):\n",
    "        count_batch = 0\n",
    "        for input_batch, target_batch in zip(all_input_batch, all_target_batch):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # input_batch : [batch_size, n_step, n_class]\n",
    "            output = model(input_batch)\n",
    "\n",
    "            # output : [batch_size, n_class], target_batch : [batch_size] (LongTensor, not one-hot)\n",
    "            loss = criterion(output, target_batch)\n",
    "            ppl = math.exp(loss.item())\n",
    "            if (count_batch + 1) % 100 == 0:\n",
    "                print('Epoch:', '%04d' % (epoch + 1), 'Batch:', '%02d' % (count_batch + 1), f'/{batch_number}',\n",
    "                      'loss =', '{:.6f}'.format(loss), 'ppl =', '{:.6}'.format(ppl))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            count_batch += 1\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'Batch:', '%02d' % (count_batch + 1), f'/{batch_number}',\n",
    "                'loss =', '{:.6f}'.format(loss), 'ppl =', '{:.6}'.format(ppl))\n",
    "\n",
    "        # valid after training one epoch\n",
    "        all_valid_batch, all_valid_target = give_valid_test.give_valid(word2number_dict, n_step)\n",
    "        all_valid_batch = torch.LongTensor(all_valid_batch).to(device)  # list to tensor\n",
    "        all_valid_target = torch.LongTensor(all_valid_target).to(device)\n",
    "\n",
    "        total_valid = len(all_valid_target)*128  # valid and test batch size is 128\n",
    "        with torch.no_grad():\n",
    "            total_loss = 0\n",
    "            count_loss = 0\n",
    "            for valid_batch, valid_target in zip(all_valid_batch, all_valid_target):\n",
    "                valid_output = model(valid_batch)\n",
    "                valid_loss = criterion(valid_output, valid_target)\n",
    "                total_loss += valid_loss.item()\n",
    "                count_loss += 1\n",
    "          \n",
    "            print(f'Valid {total_valid} samples after epoch:', '%04d' % (epoch + 1), 'loss =',\n",
    "                  '{:.6f}'.format(total_loss / count_loss),\n",
    "                  'ppl =', '{:.6}'.format(math.exp(total_loss / count_loss)))\n",
    "\n",
    "        if (epoch+1) % save_checkpoint_epoch == 0:\n",
    "            torch.save(model, f'LSTMlm_model_epoch{epoch+1}.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c14a0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_LSTMlm(select_model_path):\n",
    "    model = torch.load(select_model_path, map_location=\"cpu\")  #load the selected model\n",
    "    model.to(device)\n",
    "\n",
    "    #load the test data\n",
    "    all_test_batch, all_test_target = give_valid_test.give_test(word2number_dict, n_step)\n",
    "    all_test_batch = torch.LongTensor(all_test_batch).to(device)  # list to tensor\n",
    "    all_test_target = torch.LongTensor(all_test_target).to(device)\n",
    "    total_test = len(all_test_target)*128  # valid and test batch size is 128\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    total_loss = 0\n",
    "    count_loss = 0\n",
    "    for test_batch, test_target in zip(all_test_batch, all_test_target):\n",
    "        test_output = model(test_batch)\n",
    "        test_loss = criterion(test_output, test_target)\n",
    "        total_loss += test_loss.item()\n",
    "        count_loss += 1\n",
    "\n",
    "    print(f\"Test {total_test} samples with {select_model_path}……………………\")\n",
    "    print('loss =','{:.6f}'.format(total_loss / count_loss),\n",
    "                  'ppl =', '{:.6}'.format(math.exp(total_loss / count_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b803d295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print parameter ......\n",
      "n_step: 5\n",
      "n_hidden: 128\n",
      "batch_size: 128\n",
      "learn_rate: 0.0005\n",
      "all_epoch: 5\n",
      "emb_size: 256\n",
      "save_checkpoint_epoch: 5\n",
      "The size of the dictionary is: 7615\n",
      "generating train_batch ......\n",
      "The number of the train batch is: 603\n",
      "\n",
      "Train the LSTMLM……………………\n",
      "Net(\n",
      "  (C): Embedding(7615, 256)\n",
      "  (LSTM): NaiveCustomLSTM()\n",
      "  (W): Linear(in_features=128, out_features=7615, bias=False)\n",
      ")\n",
      "Epoch: 0001 Batch: 100 /603 loss = 6.648389 ppl = 771.54\n",
      "Epoch: 0001 Batch: 200 /603 loss = 6.369073 ppl = 583.517\n",
      "Epoch: 0001 Batch: 300 /603 loss = 6.550680 ppl = 699.72\n",
      "Epoch: 0001 Batch: 400 /603 loss = 6.775137 ppl = 875.799\n",
      "Epoch: 0001 Batch: 500 /603 loss = 6.279776 ppl = 533.669\n",
      "Epoch: 0001 Batch: 600 /603 loss = 6.386709 ppl = 593.899\n",
      "Epoch: 0001 Batch: 604 /603 loss = 5.782651 ppl = 324.619\n",
      "Valid 5504 samples after epoch: 0001 loss = 6.223718 ppl = 504.576\n",
      "Epoch: 0002 Batch: 100 /603 loss = 5.934936 ppl = 378.016\n",
      "Epoch: 0002 Batch: 200 /603 loss = 5.855211 ppl = 349.048\n",
      "Epoch: 0002 Batch: 300 /603 loss = 6.162818 ppl = 474.764\n",
      "Epoch: 0002 Batch: 400 /603 loss = 6.448459 ppl = 631.728\n",
      "Epoch: 0002 Batch: 500 /603 loss = 6.011809 ppl = 408.221\n",
      "Epoch: 0002 Batch: 600 /603 loss = 6.094572 ppl = 443.444\n",
      "Epoch: 0002 Batch: 604 /603 loss = 5.477718 ppl = 239.3\n",
      "Valid 5504 samples after epoch: 0002 loss = 6.051402 ppl = 424.708\n",
      "Epoch: 0003 Batch: 100 /603 loss = 5.739566 ppl = 310.93\n",
      "Epoch: 0003 Batch: 200 /603 loss = 5.530912 ppl = 252.374\n",
      "Epoch: 0003 Batch: 300 /603 loss = 5.910176 ppl = 368.771\n",
      "Epoch: 0003 Batch: 400 /603 loss = 6.184611 ppl = 485.224\n",
      "Epoch: 0003 Batch: 500 /603 loss = 5.828084 ppl = 339.707\n",
      "Epoch: 0003 Batch: 600 /603 loss = 5.868986 ppl = 353.89\n",
      "Epoch: 0003 Batch: 604 /603 loss = 5.262464 ppl = 192.956\n",
      "Valid 5504 samples after epoch: 0003 loss = 5.944763 ppl = 381.749\n",
      "Epoch: 0004 Batch: 100 /603 loss = 5.576888 ppl = 264.248\n",
      "Epoch: 0004 Batch: 200 /603 loss = 5.270550 ppl = 194.523\n",
      "Epoch: 0004 Batch: 300 /603 loss = 5.689806 ppl = 295.836\n",
      "Epoch: 0004 Batch: 400 /603 loss = 5.950257 ppl = 383.852\n",
      "Epoch: 0004 Batch: 500 /603 loss = 5.671126 ppl = 290.361\n",
      "Epoch: 0004 Batch: 600 /603 loss = 5.665847 ppl = 288.833\n",
      "Epoch: 0004 Batch: 604 /603 loss = 5.086224 ppl = 161.778\n",
      "Valid 5504 samples after epoch: 0004 loss = 5.876459 ppl = 356.545\n",
      "Epoch: 0005 Batch: 100 /603 loss = 5.423407 ppl = 226.65\n",
      "Epoch: 0005 Batch: 200 /603 loss = 5.054301 ppl = 156.695\n",
      "Epoch: 0005 Batch: 300 /603 loss = 5.493040 ppl = 242.995\n",
      "Epoch: 0005 Batch: 400 /603 loss = 5.735606 ppl = 309.701\n",
      "Epoch: 0005 Batch: 500 /603 loss = 5.529557 ppl = 252.032\n",
      "Epoch: 0005 Batch: 600 /603 loss = 5.473809 ppl = 238.366\n",
      "Epoch: 0005 Batch: 604 /603 loss = 4.926003 ppl = 137.828\n",
      "Valid 5504 samples after epoch: 0005 loss = 5.832593 ppl = 341.243\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    n_step = 5 # number of cells(= number of Step)\n",
    "    n_hidden = 128 # number of hidden units in one cell\n",
    "    batch_size = 128 # batch size\n",
    "    learn_rate = 0.0005\n",
    "    all_epoch = 5 #the all epoch for training\n",
    "    emb_size = 256 #embeding size\n",
    "    save_checkpoint_epoch = 5 # save a checkpoint per save_checkpoint_epoch epochs !!! Note the save path !!!\n",
    "    data_root = ''\n",
    "    train_path = os.path.join(data_root, 'train.txt') # the path of train dataset\n",
    "\n",
    "    print(\"print parameter ......\")\n",
    "    print(\"n_step:\", n_step)\n",
    "    print(\"n_hidden:\", n_hidden)\n",
    "    print(\"batch_size:\", batch_size)\n",
    "    print(\"learn_rate:\", learn_rate)\n",
    "    print(\"all_epoch:\", all_epoch)\n",
    "    print(\"emb_size:\", emb_size)\n",
    "    print(\"save_checkpoint_epoch:\", save_checkpoint_epoch)\n",
    "    #print(\"train_data:\", data_root)\n",
    "\n",
    "    word2number_dict, number2word_dict = make_dict(train_path)\n",
    "    #print(word2number_dict)\n",
    "\n",
    "    print(\"The size of the dictionary is:\", len(word2number_dict))\n",
    "    n_class = len(word2number_dict)  #n_class (= dict size)\n",
    "\n",
    "    print(\"generating train_batch ......\")\n",
    "    all_input_batch, all_target_batch = make_batch(train_path, word2number_dict, batch_size, n_step)  # make the batch\n",
    "    train_batch_list = [all_input_batch, all_target_batch]\n",
    "    \n",
    "    print(\"The number of the train batch is:\", len(all_input_batch))\n",
    "    all_input_batch = torch.LongTensor(all_input_batch).to(device)   #list to tensor\n",
    "    all_target_batch = torch.LongTensor(all_target_batch).to(device)\n",
    "    # print(all_input_batch.shape)\n",
    "    # print(all_target_batch.shape)\n",
    "    all_input_batch = all_input_batch.reshape(-1, batch_size, n_step)\n",
    "    all_target_batch = all_target_batch.reshape(-1, batch_size)\n",
    "\n",
    "    print(\"\\nTrain the LSTMLM……………………\")\n",
    "    train_LSTMlm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fdb0fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test the LSTMLM……………………\n",
      "Test 6528 samples with LSTMlm_model_epoch5.ckpt……………………\n",
      "loss = 5.775654 ppl = 322.355\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTest the LSTMLM……………………\")\n",
    "select_model_path = \"LSTMlm_model_epoch5.ckpt\"\n",
    "test_LSTMlm(select_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6dbae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
